import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error

# Generate random data for the independent variable
np.random.seed(0)
X = np.random.rand(30) * 10

# Generate the dependent variable (target) using the equation
y_true = 2 + 3*X - 0.5*X**2 + np.random.randn(30) * 2

degrees = np.arange(0, 100)
errors = []
biases = []
variances = []

for degree in degrees:
    # Transform the independent variable using polynomial features
    poly = PolynomialFeatures(degree=degree)
    X_poly = poly.fit_transform(X.reshape(-1, 1))

    # Fit the polynomial regression model
    model = LinearRegression()
    model.fit(X_poly, y_true)

    # Predict the target values
    y_pred = model.predict(X_poly)

    # Calculate bias, variance, and error
    bias = np.mean((y_pred - y_true)**2)
    variance = np.var(y_pred)
    error = np.sqrt(mean_squared_error(y_true, y_pred))  # Calculate RMSE

    biases.append(bias)
    variances.append(variance)
    errors.append(error)

# Plot the variance, RMSE, and Bias on a single axis
plt.plot(degrees, variances, label='Variance', color='orange')
plt.plot(degrees, errors, label='RMSE', color='green')
plt.plot(degrees, biases, label='Bias', color='blue')

# Set the axis labels and title
plt.xlabel('Model Complexity (Degree)')
plt.ylabel('Error / Bias / Variance')
plt.title('Bias, Variance, and RMSE')

# Display the legend
plt.legend()

# Display the plot
plt.show()
